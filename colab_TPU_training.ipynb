{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pedalnet_training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssgalitsky/PedalNetRT/blob/master/colab_TPU_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nCUd-0A_qi8"
      },
      "source": [
        " To Train models, upload the pedalnet repository to your Google Drive account and run the following code. In Colab options, go to \"Runtime\", \"Change Runtime Type\", and change hardware accelerator to \"TPU\".\n",
        " \n",
        " Note: User needs to modify the train.py script to use TPUs. Uncomment line as instructed in the file notes.\n",
        "\n",
        " Note: Having difficulty saving and loading TPU model after converting to CPU. It can be done, but currently needs some work."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHkf8SbECuIn"
      },
      "source": [
        "!git clone https://github.com/ssgalitsky/PedalNetRT.git\n",
        "\n",
        "!pip3 install torchvision\n",
        "!pip install pytorch-lightning\n",
        "\n",
        "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "!python pytorch-xla-env-setup.py --version nightly --apt-packages libomp5 libopenblas-dev\n",
        "!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.6-cp36-cp36m-linux_x86_64.whl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LXpEvx5Htpr"
      },
      "source": [
        "import torch\n",
        "use_cuda=True\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "  net.cuda()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ch_3CBmk6tqK"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4W98Rf771lR"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/PedalNetRT')\n",
        "os.getcwd()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCMJ5htaMf0B"
      },
      "source": [
        "#!ffmpeg -i \"data/guitar.wav\" -af \"pan=stereo|c0=c0|c1=c0\" \"data/guitar.wav\"\n",
        "#!ffmpeg -i \"data/flute.wav\" -af \"pan=stereo|c0=c0|c1=c0\" \"data/flute.wav\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9vktclZBGuc",
        "outputId": "27373c3a-ca15-491f-eda2-3e9be1e02624",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!python3 \"prepare_data.py\" \"/content/PedalNetRT/data/guitar.wav\" \"/content/PedalNetRT/data/flute.wav\"\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "prepare_data.py:8: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
            "  in_rate, in_data = wavfile.read(args.in_file)\n",
            "prepare_data.py:9: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
            "  out_rate, out_data = wavfile.read(args.out_file)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBb2THG2BtLm",
        "outputId": "07a834b0-8a31-4536-fa4d-22882567697a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        }
      },
      "source": [
        "\n",
        "import os\n",
        "assert os.environ['COLAB_TPU_ADDR']\n",
        "import pytorch_lightning\n",
        "!python3 \"train.py\" --batch_size=32 --max_epochs=1500 --learning_rate=3e-3 --num_channels=5 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU available: False, used: False\n",
            "TPU available: True, using: 8 TPU cores\n",
            "training on 8 TPU cores\n",
            "INIT TPU local core: 0, global rank: 0 with XLA_USE_BF16=None\n",
            "INIT TPU local core: 1, global rank: 1 with XLA_USE_BF16=None\n",
            "2020-10-12 00:48:54.013451: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "INIT TPU local core: 2, global rank: 2 with XLA_USE_BF16=None\n",
            "INIT TPU local core: 6, global rank: 6 with XLA_USE_BF16=None\n",
            "INIT TPU local core: 3, global rank: 3 with XLA_USE_BF16=None\n",
            "INIT TPU local core: 7, global rank: 7 with XLA_USE_BF16=None\n",
            "INIT TPU local core: 5, global rank: 5 with XLA_USE_BF16=None\n",
            "INIT TPU local core: 4, global rank: 4 with XLA_USE_BF16=None\n",
            "\n",
            "  | Name    | Type    | Params\n",
            "------------------------------------\n",
            "0 | wavenet | WaveNet | 1 K   \n",
            "Validation sanity check: 100% 2/2 [00:02<00:00,  1.09s/it]/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The validation_epoch_end should not return anything as of 9.1.to log, use self.log(...) or self.write(...) directly in the LightningModule\n",
            "  warnings.warn(*args, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The {log:dict keyword} was deprecated in 0.9.1 and will be removed in 1.0.0\n",
            "Please use self.log(...) inside the lightningModule instead.\n",
            "\n",
            "# log on a step or aggregate epoch metric to the logger and/or progress bar\n",
            "# (inside LightningModule)\n",
            "self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
            "  warnings.warn(*args, **kwargs)\n",
            "Epoch 0:  73% 8/11 [00:14<00:05,  1.87s/it, loss=24856916.000, v_num=0]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 0:  82% 9/11 [00:20<00:04,  2.31s/it, loss=24856916.000, v_num=0]\n",
            "Epoch 0: 100% 11/11 [00:22<00:00,  2.05s/it, loss=24856916.000, v_num=0]\n",
            "Epoch 1:  73% 8/11 [00:01<00:00,  4.03it/s, loss=16919952.000, v_num=0]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 1:  91% 10/11 [00:02<00:00,  3.47it/s, loss=16919952.000, v_num=0]\n",
            "Epoch 1: 100% 11/11 [00:03<00:00,  2.87it/s, loss=16919952.000, v_num=0]\n",
            "Epoch 2:  73% 8/11 [00:01<00:00,  5.77it/s, loss=10552642.000, v_num=0]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 2: 100% 11/11 [00:02<00:00,  4.09it/s, loss=10552642.000, v_num=0]\n",
            "Epoch 3:  73% 8/11 [00:01<00:00,  4.58it/s, loss=6461061.000, v_num=0]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 3: 100% 11/11 [00:03<00:00,  2.96it/s, loss=6461061.000, v_num=0]\n",
            "Epoch 4:  55% 6/11 [00:01<00:00,  5.21it/s, loss=3976815.500, v_num=0]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jinHl027kvhC"
      },
      "source": [
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "\n",
        "from model import PedalNet\n",
        "# Change path below to match model file\n",
        "model = PedalNet.load_from_checkpoint('lightning_logs/version_0/checkpoints/epoch=1.ckpt')\n",
        "\n",
        "# xm.save(model.state_dict(), 'tpu_to_cpu.ckpt') \n",
        "xm.save(model, 'tpu_to_cpu_model.ckpt') \n",
        "# issues loading model, see pytorch_lightning issues #2303 and #3044 (Might be completed by now)\n",
        "\n",
        "# TODO: Add code to be able to load saved model sucessfully\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}